{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b6062d84-5fb4-448b-9b0a-5f7919ba4271",
   "metadata": {},
   "source": [
    "### MERIT-Hydro‚ÄìDerived River Network For South Saskachewan River\n",
    "\n",
    "**Description**  \n",
    "The regional river network used in this study was derived directly from the **MERIT Hydro** digital elevation model (DEM) and is **independent of the MERIT-Basins product**. The river network was generated specifically for a study region in **southern Saskatchewan, Canada**, centered around **Lake Diefenbaker and the Gardiner Dam**.\n",
    "\n",
    "The study area corresponds to a regional DEM mosaic with a **lower-left corner at 50¬∞ N, 110¬∞ W** and extends to fully cover the contributing watershed upstream of Lake Diefenbaker. The resulting river network is approximately **five times denser than MERIT-Basins**, enabling finer-scale hydrologic analysis.\n",
    "\n",
    "The DEM used for river extraction was **hydrologically conditioned**, and additional corrections were applied during preprocessing to ensure consistent drainage connectivity, add sinks, and enforce realistic flow paths. Both the derived river network and the associated subbasins were further processed to ensure compatibility with the *riverlakenetwork* package.\n",
    "\n",
    "Subbasins were generated using **WhiteboxTools**; however, due to known issues related to raster-to-vector conversion (e.g., self-touching polygons, false interior holes, and topological artifacts), the resulting basin polygons **require additional post-processing**. These corrections were performed using supplementary scripts and, where necessary, external GIS tools such as **QGIS** to ensure valid geometries and correct basin topology prior to analysis.\n",
    "\n",
    "**Citation**  \n",
    "Yamazaki, D., Ikeshima, D., Sosa, J., Bates, P. D., Allen, G. H., & Pavelsky, T. M. (2019).  \n",
    "*MERIT Hydro: A high-resolution global hydrography map based on the latest topography datasets.*  \n",
    "**Water Resources Research**, 55, 5053‚Äì5073.  \n",
    "https://doi.org/10.1029/2019WR024873\n",
    "\n",
    "**Dataset Access**  \n",
    "- MERIT Hydro global hydrography dataset:  \n",
    "  https://hydro.iis.u-tokyo.ac.jp/~yamadai/MERIT_Hydro/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "46ee5df3-4f2a-44f8-8a1d-cf9d14544970",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted: /Users/shg096/Desktop/RiverLakeNetwork/examples/preparation/rivers_final_SK.shp\n",
      "Deleted: /Users/shg096/Desktop/RiverLakeNetwork/examples/preparation/basins_final_SK.shp\n",
      "Deleted: /Users/shg096/Desktop/RiverLakeNetwork/examples/preparation/rivers_final_SK.shx\n",
      "Deleted: /Users/shg096/Desktop/RiverLakeNetwork/examples/preparation/basins_final_SK.shx\n",
      "Deleted: /Users/shg096/Desktop/RiverLakeNetwork/examples/preparation/rivers_final_SK.dbf\n",
      "Deleted: /Users/shg096/Desktop/RiverLakeNetwork/examples/preparation/basins_final_SK.dbf\n",
      "Deleted: /Users/shg096/Desktop/RiverLakeNetwork/examples/preparation/basins_final_SK.prj\n",
      "Deleted: /Users/shg096/Desktop/RiverLakeNetwork/examples/preparation/rivers_final_SK.prj\n",
      "Deleted: /Users/shg096/Desktop/RiverLakeNetwork/examples/preparation/rivers_final_SK.cpg\n",
      "Deleted: /Users/shg096/Desktop/RiverLakeNetwork/examples/preparation/basins_final_SK.cpg\n",
      "Raised 1457 cells by 50.0 m\n",
      "‚úÖ DEM with wall written to: dem_with_wall.tif\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import rasterio\n",
    "from rasterio.transform import rowcol\n",
    "from rasterio.features import rasterize\n",
    "from shapely.geometry import LineString\n",
    "from whitebox.whitebox_tools import WhiteboxTools\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import sys\n",
    "import glob\n",
    "import shutil\n",
    "\n",
    "# ============================================================\n",
    "# INPUTS\n",
    "# ============================================================\n",
    "\n",
    "DEM_PATH = \"/Users/shg096/Downloads/elv_n30w120/n50w110_elv.tif\"\n",
    "\n",
    "# Lines defined by start/end lon-lat\n",
    "# Each entry: ((lon1, lat1), (lon2, lat2))\n",
    "WALL_LINES_LON_LAT = [\n",
    "    # example:\n",
    "    ((-106.41960, 50.99760), (-106.44540, 50.96720)), # Qu'appelle dam\n",
    "    ((-107.03700, 51.12200), (-107.01450, 51.09510)), # lucky lake\n",
    "    ((-107.01450, 51.09510), (-107.04560, 51.05230)), # lucky lake\n",
    "    ((-107.04560, 51.05230), (-107.06810, 51.04370)), # lucky lake\n",
    "    ((-107.08960, 51.09840), (-107.09550, 51.03680)), # lucky lake split\n",
    "    ((-106.87892, 51.25830), (-106.89287, 51.26091)), # gardiner spillway\n",
    "    ((-106.77772, 51.14780), (-106.78822, 51.15736)), # Diefenbaker lake\n",
    "    ((-107.61848, 50.66908), (-107.61762, 50.66406)), # Diefenbaker lake\n",
    "    ((-108.06965, 50.67732), (-108.06556, 50.68268)), # Diefenbaker lake\n",
    "    ((-108.06965, 50.67732), (-108.06556, 50.68268)), # Diefenbaker lake\n",
    "    ((-107.61200, 50.66485), (-107.61182, 50.66427)), # Diefenbaker lake\n",
    "    ((-108.06351, 50.68362), (-108.07337, 50.68503)), # Diefenbaker lake\n",
    "    ((-108.07053, 50.68120), (-108.07028, 50.67732)), # Diefenbaker lake\n",
    "    ((-106.71641, 51.05629), (-106.71628, 51.05257)), # Diefenbaker lake\n",
    "    ((-106.66631, 51.12303), (-106.66238, 51.12312)), # Diefenbaker lake\n",
    "]\n",
    "\n",
    "WALL_HEIGHT = 50.0      # meters\n",
    "BUFFER_CELLS = 2        # thickness of wall (cells on each side)\n",
    "OUT_DEM = \"dem_with_wall.tif\"\n",
    "\n",
    "for ext in [\"*.shp\", \"*.shx\", \"*.dbf\", \"*.prj\", \"*.cpg\", \"*.tif\", \"*.gpkg\"]:\n",
    "    for f in glob.glob(os.path.join(os.getcwd(), ext)):\n",
    "        try:\n",
    "            os.remove(f)\n",
    "            print(f\"Deleted: {f}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to delete {f}: {e}\")\n",
    "\n",
    "# ============================================================\n",
    "# READ DEM\n",
    "# ============================================================\n",
    "\n",
    "with rasterio.open(DEM_PATH) as src:\n",
    "    dem = src.read(1)\n",
    "    profile = src.profile\n",
    "    transform = src.transform\n",
    "    nodata = src.nodata\n",
    "    height, width = dem.shape\n",
    "    res_x = abs(transform.a)  # pixel size (deg for MERIT)\n",
    "\n",
    "dem_out = dem.copy()\n",
    "\n",
    "# ============================================================\n",
    "# BUILD LINE GEOMETRIES (lon/lat CRS)\n",
    "# ============================================================\n",
    "\n",
    "lines = []\n",
    "for (lon1, lat1), (lon2, lat2) in WALL_LINES_LON_LAT:\n",
    "    lines.append(LineString([(lon1, lat1), (lon2, lat2)]))\n",
    "\n",
    "if not lines:\n",
    "    raise RuntimeError(\"‚ùå No wall lines provided\")\n",
    "\n",
    "# ============================================================\n",
    "# BUFFER LINES (convert cells ‚Üí map units)\n",
    "# ============================================================\n",
    "\n",
    "buffer_dist = BUFFER_CELLS * res_x\n",
    "buffered_lines = [ln.buffer(buffer_dist) for ln in lines]\n",
    "\n",
    "# ============================================================\n",
    "# RASTERIZE WALL MASK\n",
    "# ============================================================\n",
    "\n",
    "wall_mask = rasterize(\n",
    "    [(geom, 1) for geom in buffered_lines],\n",
    "    out_shape=(height, width),\n",
    "    transform=transform,\n",
    "    fill=0,\n",
    "    dtype=np.uint8\n",
    ")\n",
    "\n",
    "# ============================================================\n",
    "# APPLY WALL HEIGHT\n",
    "# ============================================================\n",
    "\n",
    "valid = (wall_mask == 1)\n",
    "if nodata is not None:\n",
    "    valid &= (dem_out != nodata)\n",
    "\n",
    "dem_out[valid] += WALL_HEIGHT\n",
    "\n",
    "print(f\"Raised {valid.sum()} cells by {WALL_HEIGHT} m\")\n",
    "\n",
    "# ============================================================\n",
    "# WRITE OUTPUT DEM\n",
    "# ============================================================\n",
    "\n",
    "with rasterio.open(OUT_DEM, \"w\", **profile) as dst:\n",
    "    dst.write(dem_out, 1)\n",
    "\n",
    "print(f\"‚úÖ DEM with wall written to: {OUT_DEM}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e102769a-d988-4867-a391-6d7808811c8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Artificial sink cells (row, col): [(4712, 3525), (4708, 3486), (4975, 2990), (4622, 2387), (4690, 2295), (4726, 2829), (4844, 1881), (4796, 1985), (4508, 1775), (4354, 3204), (4621, 4392), (4716, 3521)]\n",
      "‚úÖ ALL DONE ‚Äî everything created in current folder\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# USER INPUTS\n",
    "# ============================================================\n",
    "\n",
    "DEM_PATH = \"dem_with_wall.tif\" # from merit hydro\n",
    "\n",
    "# sink point to alter the non contributing area when needed\n",
    "SINK_POINTS_LONLAT = [\n",
    "    (-107.06290, 51.07230),\n",
    "    (-107.09460, 51.07610),\n",
    "    (-107.50830, 50.85320),\n",
    "    (-108.01120, 51.14725),\n",
    "    (-108.08740, 51.09047),\n",
    "    (-107.64240, 51.06080),\n",
    "    (-108.43274, 50.96276),\n",
    "    (-108.34569, 51.00249),\n",
    "    (-108.52113, 51.24219),\n",
    "    (-107.33030, 51.37085),\n",
    "    (-106.34001, 51.14840),\n",
    "    (-107.06583, 51.06914),\n",
    "    \n",
    "]\n",
    "\n",
    "SINK_DEPTH = 20.0\n",
    "FILL_DEPTH = 2.0\n",
    "ACC_THRESHOLD = 1000\n",
    "\n",
    "# ============================================================\n",
    "# OUTPUT FILE NAMES (SAME FOLDER AS SCRIPT)\n",
    "# ============================================================\n",
    "\n",
    "DEM_SINKED = \"dem_sinked.tif\"\n",
    "DEM_FILLED = \"dem_filled.tif\"\n",
    "FLOW_DIR   = \"flow_dir.tif\"\n",
    "FLOW_ACC   = \"flow_acc.tif\"\n",
    "\n",
    "RIVERS_R   = \"rivers.tif\"\n",
    "RIVERS_SHP = \"rivers.shp\"\n",
    "\n",
    "POUR_PTS   = \"pour_points.tif\"\n",
    "BASINS_R   = \"basins.tif\"\n",
    "BASINS_SHP = \"basins.shp\"\n",
    "\n",
    "# ============================================================\n",
    "# SETUP WHITEBOX (CRITICAL)\n",
    "# ============================================================\n",
    "\n",
    "wbt = WhiteboxTools()\n",
    "wbt.verbose = False\n",
    "wbt.work_dir = os.getcwd()   # üîë required, but no directory handling needed\n",
    "\n",
    "# ============================================================\n",
    "# STEP 1 ‚Äî READ DEM\n",
    "# ============================================================\n",
    "\n",
    "with rasterio.open(DEM_PATH) as src:\n",
    "    dem = src.read(1)\n",
    "    profile = src.profile\n",
    "    transform = src.transform\n",
    "\n",
    "dem_sinked = dem.copy()\n",
    "\n",
    "# ============================================================\n",
    "# STEP 2 ‚Äî CONVERT LON/LAT ‚Üí ROW/COL\n",
    "# ============================================================\n",
    "\n",
    "sink_rc = []\n",
    "for lon, lat in SINK_POINTS_LONLAT:\n",
    "    r, c = rowcol(transform, lon, lat)\n",
    "    sink_rc.append((r, c))\n",
    "\n",
    "print(\"Artificial sink cells (row, col):\", sink_rc)\n",
    "\n",
    "# ============================================================\n",
    "# STEP 3 ‚Äî BURN ARTIFICIAL SINKS\n",
    "# ============================================================\n",
    "\n",
    "for r, c in sink_rc:\n",
    "    if 0 <= r < dem.shape[0] and 0 <= c < dem.shape[1]:\n",
    "        dem_sinked[r, c] -= SINK_DEPTH\n",
    "\n",
    "with rasterio.open(DEM_SINKED, \"w\", **profile) as dst:\n",
    "    dst.write(dem_sinked, 1)\n",
    "\n",
    "# ============================================================\n",
    "# STEP 4 ‚Äî FILL ONLY SMALL NATURAL DEPRESSIONS\n",
    "# ============================================================\n",
    "\n",
    "wbt.fill_depressions(\n",
    "    DEM_SINKED,\n",
    "    output=DEM_FILLED,\n",
    "    max_depth=FILL_DEPTH\n",
    ")\n",
    "\n",
    "if not os.path.exists(DEM_FILLED):\n",
    "    sys.exit(\"‚ùå fill_depressions failed\")\n",
    "\n",
    "# ============================================================\n",
    "# STEP 5 ‚Äî FLOW DIRECTION\n",
    "# ============================================================\n",
    "\n",
    "wbt.d8_pointer(\n",
    "    DEM_FILLED,\n",
    "    output=FLOW_DIR\n",
    ")\n",
    "\n",
    "if not os.path.exists(FLOW_DIR):\n",
    "    sys.exit(\"‚ùå flow direction failed\")\n",
    "\n",
    "# ============================================================\n",
    "# STEP 6 ‚Äî FLOW ACCUMULATION\n",
    "# ============================================================\n",
    "\n",
    "wbt.d8_flow_accumulation(\n",
    "    i=DEM_FILLED,\n",
    "    output=FLOW_ACC,\n",
    "    out_type=\"cells\"\n",
    ")\n",
    "\n",
    "if not os.path.exists(FLOW_ACC):\n",
    "    sys.exit(\"‚ùå flow accumulation failed\")\n",
    "\n",
    "# ============================================================\n",
    "# STEP 7 ‚Äî EXTRACT RIVER NETWORK\n",
    "# ============================================================\n",
    "\n",
    "wbt.extract_streams(\n",
    "    flow_accum=FLOW_ACC,\n",
    "    output=RIVERS_R,\n",
    "    threshold=ACC_THRESHOLD\n",
    ")\n",
    "\n",
    "if not os.path.exists(RIVERS_R):\n",
    "    sys.exit(\"‚ùå stream extraction failed\")\n",
    "\n",
    "# ============================================================\n",
    "# STEP 8 ‚Äî RIVERS ‚Üí SHAPEFILE (FIXED)\n",
    "# ============================================================\n",
    "\n",
    "wbt.raster_streams_to_vector(\n",
    "    streams=RIVERS_R,\n",
    "    d8_pntr=FLOW_DIR,\n",
    "    output=RIVERS_SHP\n",
    ")\n",
    "\n",
    "if not os.path.exists(RIVERS_SHP):\n",
    "    sys.exit(\"‚ùå river vectorization failed\")\n",
    "\n",
    "# ============================================================\n",
    "# STEP 9 ‚Äî BASIN CREATION\n",
    "# ============================================================\n",
    "wbt.subbasins(\n",
    "    d8_pntr=FLOW_DIR,\n",
    "    streams=RIVERS_R,\n",
    "    output=BASINS_R\n",
    ")\n",
    "\n",
    "if not os.path.exists(BASINS_R):\n",
    "    sys.exit(\"‚ùå river vectorization failed\")\n",
    "\n",
    "# ============================================================\n",
    "# STEP 10 ‚Äî BASIN ‚Üí SHAPEFILE (FIXED)\n",
    "# ============================================================\n",
    "\n",
    "# Convert subbasins to polygons\n",
    "wbt.raster_to_vector_polygons(\n",
    "    i=BASINS_R,\n",
    "    output=BASINS_SHP\n",
    ")\n",
    "\n",
    "if not os.path.exists(BASINS_SHP):\n",
    "    sys.exit(\"‚ùå river vectorization failed\")\n",
    "\n",
    "print(\"‚úÖ ALL DONE ‚Äî everything created in current folder\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aa89257-b6fe-4e0c-a2d4-287f19b9e4fc",
   "metadata": {},
   "source": [
    "# **Basins clean up**\n",
    "## Clean up the invalid geometry in basins with QGIS  or other GIS programs and resave it to the same location before continuing the next steps\n",
    "-------\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d98a3085-f208-4874-bf1c-9c1e0c673c02",
   "metadata": {},
   "source": [
    "-----\n",
    "# **ID assigning to rivers and basins**\n",
    "## In the following, the IDs of rivers and basins are assigned to each other so the associated river segment and basins have the same ID."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b0f85fba-3437-4ab2-81c1-9e4fd6a97390",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shg096/Desktop/RiverLakeNetwork/env/RiverLakeEnv/lib/python3.9/site-packages/pyogrio/raw.py:198: RuntimeWarning: basins.shp contains polygon(s) with rings with invalid winding order. Autocorrecting them, but that shapefile should be corrected using ogr2ogr for example.\n",
      "  return ogr_read(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 19910 rivers\n",
      "Loaded 19923 basins\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shg096/Desktop/RiverLakeNetwork/env/RiverLakeEnv/lib/python3.9/site-packages/pyogrio/geopandas.py:710: UserWarning: 'crs' was not provided.  The output dataset will not have projection information defined and may not be usable in other systems.\n",
      "  write(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ö†Ô∏è  Removing 33 subbasins without a river start point\n",
      "‚úÖ Remaining basins: 19890\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shg096/Desktop/RiverLakeNetwork/env/RiverLakeEnv/lib/python3.9/site-packages/pyogrio/geopandas.py:710: UserWarning: 'crs' was not provided.  The output dataset will not have projection information defined and may not be usable in other systems.\n",
      "  write(\n",
      "/Users/shg096/Desktop/RiverLakeNetwork/env/RiverLakeEnv/lib/python3.9/site-packages/pyogrio/geopandas.py:710: UserWarning: 'crs' was not provided.  The output dataset will not have projection information defined and may not be usable in other systems.\n",
      "  write(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Output written: basins_with_linkno.shp\n"
     ]
    }
   ],
   "source": [
    "import geopandas as gpd\n",
    "from shapely.geometry import Point, Polygon, MultiPolygon\n",
    "\n",
    "# ============================================================\n",
    "# FILES\n",
    "# ============================================================\n",
    "\n",
    "RIVERS_SHP = \"rivers.shp\"\n",
    "BASINS_IN  = \"basins.shp\"\n",
    "BASINS_OUT = \"basins_with_linkno.shp\"\n",
    "RIVERS_OUT = \"rivers_with_linkno.shp\"\n",
    "LINK_FIELD = \"link_id\" # link_id field in the rivers that should be assgined to basins\n",
    "\n",
    "# ============================================================\n",
    "# LOAD DATA\n",
    "# ============================================================\n",
    "\n",
    "rivers = gpd.read_file(RIVERS_SHP)\n",
    "basins = gpd.read_file(BASINS_IN)\n",
    "\n",
    "if LINK_FIELD not in rivers.columns:\n",
    "    rivers[LINK_FIELD] = np.arange(1, len(rivers) + 1)\n",
    "\n",
    "print(f\"Loaded {len(rivers)} rivers\")\n",
    "print(f\"Loaded {len(basins)} basins\")\n",
    "\n",
    "# ============================================================\n",
    "# EXTRACT START POINT OF EACH RIVER\n",
    "# ============================================================\n",
    "\n",
    "records = []\n",
    "\n",
    "for _, row in rivers.iterrows():\n",
    "    geom = row.geometry\n",
    "\n",
    "    if geom.geom_type == \"LineString\":\n",
    "        coords = list(geom.coords)\n",
    "    elif geom.geom_type == \"MultiLineString\":\n",
    "        coords = list(geom.geoms[0].coords)\n",
    "    else:\n",
    "        raise TypeError(\"River geometry must be LineString or MultiLineString\")\n",
    "\n",
    "    records.append({\n",
    "        LINK_FIELD: row[LINK_FIELD],\n",
    "        \"geometry\": Point(coords[0])\n",
    "    })\n",
    "\n",
    "river_starts = gpd.GeoDataFrame(records, crs=rivers.crs)\n",
    "river_starts.to_file(\"starting_points.shp\")\n",
    "river_starts[\"geometry\"] = river_starts.geometry.buffer(0.00000001)\n",
    "\n",
    "# ============================================================\n",
    "# SPATIAL JOIN: BASIN ‚Üê RIVER START\n",
    "# ============================================================\n",
    "\n",
    "joined = gpd.sjoin(\n",
    "    basins,\n",
    "    river_starts,\n",
    "    how=\"left\",\n",
    "    predicate=\"intersects\"\n",
    ")\n",
    "\n",
    "# ============================================================\n",
    "# REPORT & REMOVE UNMATCHED BASINS\n",
    "# ============================================================\n",
    "\n",
    "missing_mask = joined[LINK_FIELD].isna()\n",
    "n_missing = missing_mask.sum()\n",
    "\n",
    "if n_missing > 0:\n",
    "    print(f\"‚ö†Ô∏è  Removing {n_missing} subbasins without a river start point\")\n",
    "\n",
    "# Keep only valid basins\n",
    "basins_out = basins.loc[~missing_mask].copy()\n",
    "basins_out[LINK_FIELD] = joined.loc[~missing_mask, LINK_FIELD].values\n",
    "\n",
    "print(f\"‚úÖ Remaining basins: {len(basins_out)}\")\n",
    "\n",
    "# ============================================================\n",
    "# SAVE OUTPUT\n",
    "# ============================================================\n",
    "\n",
    "rivers = rivers[rivers[\"link_id\"].isin(set(basins_out[\"link_id\"].astype(int)))]\n",
    "\n",
    "basins_out.to_file(BASINS_OUT)\n",
    "rivers.to_file(RIVERS_OUT)\n",
    "\n",
    "print(f\"‚úÖ Output written: {BASINS_OUT}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f3d384e-af07-43a6-99ba-0e5e217379ba",
   "metadata": {},
   "source": [
    "# **Assinging the next down ID in the river network**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "92bff319-aaea-4845-bca0-a7fd8200c48c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 19890 river segments\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shg096/Desktop/RiverLakeNetwork/env/RiverLakeEnv/lib/python3.9/site-packages/pyogrio/geopandas.py:710: UserWarning: 'crs' was not provided.  The output dataset will not have projection information defined and may not be usable in other systems.\n",
      "  write(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ DONE\n",
      "Saved: rivers_with_linkno_ds.shp\n"
     ]
    }
   ],
   "source": [
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "from shapely.geometry import LineString, MultiLineString\n",
    "from scipy.spatial import cKDTree\n",
    "\n",
    "# ============================================================\n",
    "# USER INPUTS\n",
    "# ============================================================\n",
    "\n",
    "RIVERS_SHP = \"rivers_with_linkno.shp\"  # input shapefile\n",
    "ID_FIELD   = \"link_id\"        # <-- CHANGE THIS if needed\n",
    "OUT_SHP    = \"rivers_with_linkno_ds.shp\"\n",
    "\n",
    "DIST_TOL   = 1e-6             # distance tolerance (units of CRS)\n",
    "\n",
    "# ============================================================\n",
    "# LOAD RIVERS\n",
    "# ============================================================\n",
    "\n",
    "gdf = gpd.read_file(RIVERS_SHP)\n",
    "\n",
    "if ID_FIELD not in gdf.columns:\n",
    "    raise ValueError(f\"ID field '{ID_FIELD}' not found\")\n",
    "\n",
    "print(f\"Loaded {len(gdf)} river segments\")\n",
    "\n",
    "# ============================================================\n",
    "# FUNCTIONS\n",
    "# ============================================================\n",
    "\n",
    "def get_start_end(geom):\n",
    "    \"\"\"Return (start_point, end_point) of a line geometry\"\"\"\n",
    "    if isinstance(geom, LineString):\n",
    "        coords = list(geom.coords)\n",
    "    elif isinstance(geom, MultiLineString):\n",
    "        coords = list(geom.geoms[0].coords)\n",
    "    else:\n",
    "        raise TypeError(\"Geometry must be LineString or MultiLineString\")\n",
    "\n",
    "    return np.array(coords[0]), np.array(coords[-1])\n",
    "\n",
    "# ============================================================\n",
    "# EXTRACT START / END POINTS\n",
    "# ============================================================\n",
    "\n",
    "starts = []\n",
    "ends = []\n",
    "ids = []\n",
    "\n",
    "for _, row in gdf.iterrows():\n",
    "    s, e = get_start_end(row.geometry)\n",
    "    starts.append(s)\n",
    "    ends.append(e)\n",
    "    ids.append(row[ID_FIELD])\n",
    "\n",
    "starts = np.array(starts)\n",
    "ends   = np.array(ends)\n",
    "ids    = np.array(ids)\n",
    "\n",
    "# ============================================================\n",
    "# BUILD KD-TREE ON START POINTS\n",
    "# ============================================================\n",
    "\n",
    "tree = cKDTree(starts)\n",
    "\n",
    "# ============================================================\n",
    "# FIND DOWNSTREAM SEGMENT\n",
    "# ============================================================\n",
    "\n",
    "down_ids = []\n",
    "\n",
    "for i, end_pt in enumerate(ends):\n",
    "    dist, idx = tree.query(end_pt, k=2)\n",
    "\n",
    "    # idx[0] is usually self ‚Üí check idx[1]\n",
    "    candidate_idx = idx[1] if idx[0] == i else idx[0]\n",
    "    candidate_dist = dist[1] if idx[0] == i else dist[0]\n",
    "\n",
    "    if candidate_dist <= DIST_TOL:\n",
    "        down_ids.append(ids[candidate_idx])\n",
    "    else:\n",
    "        down_ids.append(-9999)\n",
    "\n",
    "# ============================================================\n",
    "# ATTACH RESULTS\n",
    "# ============================================================\n",
    "\n",
    "gdf[\"link_id\"] = ids\n",
    "gdf[\"ds_link_id\"] = down_ids\n",
    "\n",
    "# ============================================================\n",
    "# SAVE OUTPUT\n",
    "# ============================================================\n",
    "\n",
    "gdf.to_file(OUT_SHP)\n",
    "\n",
    "print(\"‚úÖ DONE\")\n",
    "print(f\"Saved: {OUT_SHP}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21d67675-2134-447f-a5f9-008ba25d592e",
   "metadata": {},
   "source": [
    "# **Assinging the unitarea and uparea**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b4dad663-9826-4111-8e63-79bc0d90bdc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 19890 rivers\n",
      "Loaded 19890 basins\n",
      "‚ö†Ô∏è Rivers CRS missing ‚Üí assigning EPSG:4326 (WGS84)\n",
      "‚ö†Ô∏è Basins CRS missing ‚Üí assigning EPSG:4326 (WGS84)\n",
      "Using metric CRS for calculations: EPSG:6933\n",
      "‚úÖ DONE\n",
      "Saved: rivers_final_SK.shp\n",
      "Saved: basins_final_SK.shp\n"
     ]
    }
   ],
   "source": [
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pyproj import CRS\n",
    "\n",
    "# ============================================================\n",
    "# INPUTS\n",
    "# ============================================================\n",
    "\n",
    "RIVERS_IN  = \"rivers_with_linkno_ds.shp\"\n",
    "BASINS_IN  = \"basins_with_linkno.shp\"\n",
    "\n",
    "RIVERS_OUT = \"rivers_final_SK.shp\"\n",
    "BASINS_OUT = \"basins_final_SK.shp\"\n",
    "\n",
    "LINK = \"link_id\"\n",
    "DOWN = \"ds_link_id\"\n",
    "\n",
    "# ============================================================\n",
    "# LOAD DATA\n",
    "# ============================================================\n",
    "\n",
    "rivers = gpd.read_file(RIVERS_IN)\n",
    "basins = gpd.read_file(BASINS_IN)\n",
    "\n",
    "print(f\"Loaded {len(rivers)} rivers\")\n",
    "print(f\"Loaded {len(basins)} basins\")\n",
    "\n",
    "from pyproj import CRS\n",
    "\n",
    "# ============================================================\n",
    "# ENSURE CRS EXISTS\n",
    "# ============================================================\n",
    "\n",
    "if rivers.crs is None:\n",
    "    print(\"‚ö†Ô∏è Rivers CRS missing ‚Üí assigning EPSG:4326 (WGS84)\")\n",
    "    rivers = rivers.set_crs(epsg=4326)\n",
    "\n",
    "if basins.crs is None:\n",
    "    print(\"‚ö†Ô∏è Basins CRS missing ‚Üí assigning EPSG:4326 (WGS84)\")\n",
    "    basins = basins.set_crs(epsg=4326)\n",
    "\n",
    "# ============================================================\n",
    "# CHOOSE METRIC CRS (GLOBAL EQUAL-AREA)\n",
    "# ============================================================\n",
    "\n",
    "metric_crs = CRS.from_epsg(6933)   # WGS 84 / NSIDC EASE-Grid 2.0 Global (equal-area)\n",
    "\n",
    "print(f\"Using metric CRS for calculations: {metric_crs.to_string()}\")\n",
    "\n",
    "# ============================================================\n",
    "# TEMPORARY REPROJECT (METRICS ONLY)\n",
    "# ============================================================\n",
    "\n",
    "rivers_m = rivers.to_crs(metric_crs)\n",
    "basins_m = basins.to_crs(metric_crs)\n",
    "\n",
    "# ============================================================\n",
    "# TEMPORARY REPROJECT (FOR METRICS ONLY)\n",
    "# ============================================================\n",
    "\n",
    "rivers_m = rivers.to_crs(metric_crs)\n",
    "basins_m = basins.to_crs(metric_crs)\n",
    "\n",
    "# ============================================================\n",
    "# CALCULATE AREA & LENGTH\n",
    "# ============================================================\n",
    "\n",
    "basins[\"unitarea\"] = basins_m.area / 1e6\n",
    "rivers[\"length\"]     = rivers_m.length / 1000.0\n",
    "\n",
    "# ============================================================\n",
    "# PASS UNIT AREA TO RIVERS\n",
    "# ============================================================\n",
    "\n",
    "area_map = dict(zip(basins[LINK], basins[\"unitarea\"]))\n",
    "rivers[\"unitarea\"] = rivers[LINK].map(area_map)\n",
    "\n",
    "# ============================================================\n",
    "# UPSTREAM AREA CALCULATION\n",
    "# ============================================================\n",
    "\n",
    "# Build downstream ‚Üí upstream graph\n",
    "upstream = {lid: [] for lid in rivers[LINK]}\n",
    "\n",
    "for _, r in rivers.iterrows():\n",
    "    if r[DOWN] in upstream:\n",
    "        upstream[r[DOWN]].append(r[LINK])\n",
    "\n",
    "# Recursive accumulation\n",
    "from functools import lru_cache\n",
    "\n",
    "@lru_cache(None)\n",
    "def compute_uparea(link):\n",
    "    area = area_map.get(link, 0.0)\n",
    "    for up in upstream.get(link, []):\n",
    "        area += compute_uparea(up)\n",
    "    return area\n",
    "\n",
    "rivers[\"uparea\"] = rivers[LINK].apply(compute_uparea)\n",
    "basins[\"uparea\"] = basins[LINK].apply(compute_uparea)\n",
    "\n",
    "# ============================================================\n",
    "# FINAL CLEANUP\n",
    "# ============================================================\n",
    "\n",
    "# Ensure numeric types\n",
    "for col in [\"unitarea\", \"uparea\"]:\n",
    "    basins[col] = basins[col].astype(float)\n",
    "    rivers[col] = rivers[col].astype(float)\n",
    "\n",
    "rivers[\"length\"] = rivers[\"length\"].astype(float)\n",
    "\n",
    "# ============================================================\n",
    "# SAVE (GEOMETRY UNCHANGED)\n",
    "# ============================================================\n",
    "\n",
    "rivers.to_file(RIVERS_OUT)\n",
    "basins.to_file(BASINS_OUT)\n",
    "\n",
    "print(\"‚úÖ DONE\")\n",
    "print(f\"Saved: {RIVERS_OUT}\")\n",
    "print(f\"Saved: {BASINS_OUT}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3bdc883b-5f08-4cda-a532-c97bc0d90c63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted: rivers_with_linkno_ds.shp\n",
      "Deleted: rivers_with_linkno_ds.shx\n",
      "Deleted: rivers_with_linkno_ds.dbf\n",
      "Deleted: rivers_with_linkno_ds.cpg\n",
      "Deleted: starting_points.shp\n",
      "Deleted: starting_points.shx\n",
      "Deleted: starting_points.dbf\n",
      "Deleted: starting_points.cpg\n",
      "Deleted: basins.shp\n",
      "Deleted: basins.shx\n",
      "Deleted: basins.dbf\n",
      "Deleted: basins.prj\n",
      "Deleted: basins_with_linkno.shp\n",
      "Deleted: basins_with_linkno.shx\n",
      "Deleted: basins_with_linkno.dbf\n",
      "Deleted: basins_with_linkno.cpg\n",
      "Deleted: rivers_with_linkno.shp\n",
      "Deleted: rivers_with_linkno.shx\n",
      "Deleted: rivers_with_linkno.dbf\n",
      "Deleted: rivers_with_linkno.cpg\n",
      "Deleted: rivers.shp\n",
      "Deleted: rivers.shx\n",
      "Deleted: rivers.dbf\n",
      "Deleted: dem_with_wall.tif\n",
      "Deleted: dem_filled.tif\n",
      "Deleted: basins.tif\n",
      "Deleted: rivers.tif\n",
      "Deleted: flow_dir.tif\n",
      "Deleted: flow_acc.tif\n",
      "Deleted: dem_sinked.tif\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "\n",
    "# ============================================================\n",
    "# FILES TO KEEP (without extensions)\n",
    "# ============================================================\n",
    "keep_files = [\"rivers_final_SK\", \"basins_final_SK\"]\n",
    "\n",
    "# ============================================================\n",
    "# SHAPEFILE-RELATED EXTENSIONS\n",
    "# ============================================================\n",
    "shp_exts = [\".shp\", \".shx\", \".dbf\", \".prj\", \".cpg\"]\n",
    "raster_exts = [\".tif\", \".tiff\"]\n",
    "\n",
    "# ============================================================\n",
    "# DELETE UNNEEDED FILES\n",
    "# ============================================================\n",
    "\n",
    "# Delete shapefiles not in keep_files\n",
    "for f in glob.glob(\"*.shp\"):\n",
    "    basename = os.path.splitext(f)[0]\n",
    "    if basename not in keep_files:\n",
    "        for ext in shp_exts:\n",
    "            target = f\"{basename}{ext}\"\n",
    "            if os.path.exists(target):\n",
    "                try:\n",
    "                    os.remove(target)\n",
    "                    print(f\"Deleted: {target}\")\n",
    "                except Exception as e:\n",
    "                    print(f\"Failed to delete {target}: {e}\")\n",
    "\n",
    "# Delete all raster files except final DEM-derived outputs (if any)\n",
    "for f in glob.glob(\"*.tif\") + glob.glob(\"*.tiff\"):\n",
    "    if f not in []:  # leave empty or list specific files to keep\n",
    "        try:\n",
    "            os.remove(f)\n",
    "            print(f\"Deleted: {f}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to delete {f}: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fe18b375-6c46-4104-9923-e3c23dada2e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ asset folder refreshed and files moved successfully\n"
     ]
    }
   ],
   "source": [
    "asset_dir = \"assets\"\n",
    "if os.path.exists(asset_dir):\n",
    "    shutil.rmtree(asset_dir)\n",
    "os.makedirs(asset_dir)\n",
    "patterns = [\n",
    "    \"basins_final_SK.*\",\n",
    "    \"rivers_final_SK.*\",\n",
    "]\n",
    "for pattern in patterns:\n",
    "    for file in glob.glob(pattern):\n",
    "        shutil.move(file, os.path.join(asset_dir, os.path.basename(file)))\n",
    "\n",
    "print(\"‚úÖ asset folder refreshed and files moved successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be8c268a-e8b2-4f59-88fb-c8059317b672",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (RiverLakeEnv)",
   "language": "python",
   "name": "riverlakeenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
