{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "81128553-fdb0-4c66-b66d-e9c5cc99266b",
   "metadata": {},
   "source": [
    "## Datasets Used\n",
    "\n",
    "### 1. MERIT-Hydro Derived River Network\n",
    "\n",
    "**Description**  \n",
    "The regional river network used in this study is independent of the MERIT‑Basins and was specifically derived from **MERIT Hydro** DEM for a region in Canada. This derived river network is 5 times denser than MERIT-Basins. Some preprocessing is applied, as explained here, to make both the derived river network and subbasins ready to be used with the riverlakenetwork package.\n",
    "\n",
    "**Citation**  \n",
    "Yamazaki, D., Ikeshima, D., Sosa, J., Bates, P. D., Allen, G. H., & Pavelsky, T. M. (2019).  \n",
    "*MERIT Hydro: A high‑resolution global hydrography map based on the latest topography datasets.*  \n",
    "**Water Resources Research**, 55, 5053–5073.  \n",
    "https://doi.org/10.1029/2019WR024873\n",
    "\n",
    "**Dataset Access**  \n",
    "- MERIT Hydro global hydrography dataset:  \n",
    "  https://hydro.iis.u-tokyo.ac.jp/~yamadai/MERIT_Hydro/\n",
    "\n",
    "---\n",
    "\n",
    "### 2. HydroLAKES (Version 1)\n",
    "\n",
    "**Description**  \n",
    "A global vector database of lakes and reservoirs, providing detailed information on lake shorelines, surface area, volume, depth estimates, and hydrological connectivity. HydroLAKES is widely used in global hydrology and water resources studies.\n",
    "\n",
    "**Citation**  \n",
    "Messager, M. L., Lehner, B., Grill, G., Nedeva, I., & Schmitt, O. (2016).  \n",
    "*Estimating the volume and age of water stored in global lakes using a geostatistical approach.*  \n",
    "**Nature Communications**, 7, 13603.  \n",
    "https://doi.org/10.1038/ncomms13603\n",
    "\n",
    "**Dataset Access**  \n",
    "- HydroLAKES product page:  \n",
    "  https://www.hydrosheds.org/products/hydrolakes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16675c6b-c32d-4f8b-8637-2f4ea3772c3d",
   "metadata": {},
   "source": [
    "### Assigning parameters and folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "50635807-5673-496c-846c-5bbee3822b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# outputfolder for where the files will be sitting\n",
    "OutFolder = '/Users/shg096/Desktop/LakeRiverOut/MERITDerivedSK/'\n",
    "\n",
    "# location of MERIT-Basin bug fixed files\n",
    "# run the script under the preparation to get the rivers_final_SK and basins_final_SK\n",
    "riv_file=\"/Users/shg096/Desktop/RiverLakeNetwork/examples/preparation/rivers_final_SK.shp\"\n",
    "cat_file=\"/Users/shg096/Desktop/RiverLakeNetwork/examples/preparation/basins_final_SK.shp\"\n",
    "\n",
    "# location of HydroLAKES\n",
    "lake_file = '/Volumes/F:/hydrography/hydrolakes/HydroLAKES_polys_v10_shp/HydroLAKES_polys_v10_shp/HydroLAKES_polys_v10.shp'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d2b002ab-19e6-4879-a9ee-fb1af8c6e464",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the needed packages\n",
    "import os\n",
    "import shutil\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from   riverlakenetwork import Utility, BurnLakes\n",
    "import warnings; warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dcad670f-a08e-4248-bdde-a8e03dc92426",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load hydrolakeDataset\n",
    "lake = gpd.read_file(lake_file) # read the hydrolake dataset\n",
    "# merge lake Michigan and Huron as they are hydraulically connected\n",
    "lake = Utility.FixHydroLAKESv1(lake, merge_lakes={\"Michigan+Huron\": [6, 8]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a5fabbfd-d2f5-43a5-85ed-da95dd268174",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=======================================================================\n",
      "=== Input loader started at : 2026-01-03 18:39:18  ===\n",
      "riv: Loaded\n",
      "riv_dict: {'COMID': {'col': 'link_id'}, 'NextDownCOMID': {'col': 'ds_link_id'}, 'length': {'col': 'length'}, 'uparea': {'col': 'uparea', 'unit': 'km2'}}\n",
      "cat: Loaded\n",
      "cat_dict: {'COMID': {'col': 'link_id'}, 'unitarea': {'col': 'unitarea', 'unit': 'km2'}}\n",
      "lake: Loaded\n",
      "lake_dict: {'LakeCOMID': {'col': 'Hylak_id'}, 'unitarea': {'col': 'Lake_area', 'unit': 'km2'}}\n",
      "=== Input loader finished at: 2026-01-03 18:39:19  ===\n",
      "=== Input loader took      : 0:00:00.582663  ===========================\n",
      "=======================================================================\n",
      "========================================================================\n",
      "=== Input checker started at : 2026-01-03 18:39:19  ===\n",
      "Subbasin and lake area units are consistent: km2\n",
      "riv CRS: EPSG:4326\n",
      "cat CRS: EPSG:4326\n",
      "lake CRS: EPSG:4326\n",
      "✅ No loop detected in network topology\n",
      "=== Input checker finished at: 2026-01-03 18:39:21  ===\n",
      "=== Input checker took      : 0:00:01.963581  ===========================\n",
      "========================================================================\n",
      "==========================================================================\n",
      "=== Resolving lakes started at : 2026-01-03 18:39:21  ===\n",
      "==== Number of lakes after subsetting: 4029 ====\n",
      "==== Number of lakes after removing intersection with only one lake: 1012 ====\n",
      "==== Number of lakes after removing lakes that do not touch starting or ending points of river segments: 828 ====\n",
      "==== Number of lakes after removing lakes that do touch only one starting or ending points of river segments: 792 ====\n",
      "==== Number of lakes after removing lakes that do intersect with only one river segment: 792 ====\n",
      "==== Number of lakes after removing lakes that do have exactly the same uparea for their maximume uparea for various: 792 ====\n",
      "==== Number of lakes after removing lakes from segments that intersect with more than 3 lakes: 792 ====\n",
      "==== Number of lakes after identifying the graph number within a lake: 791 ====\n",
      "=== Resolving lakes finished at: 2026-01-03 18:40:08  ===\n",
      "=== Resolving lakes took      : 0:00:47.473069  ===========================\n",
      "==========================================================================\n",
      "=============================================================================\n",
      "=== Network correction started at : 2026-01-03 18:40:08  ===\n",
      "=== Network correction finished at: 2026-01-03 18:41:38  ===\n",
      "=== Network correction took      : 0:01:29.507307  ===========================\n",
      "=============================================================================\n",
      "=============================================================================\n",
      "=== Output checker started at : 2026-01-03 18:41:38  =======\n",
      "✓ No lake outlet topology issues found.\n",
      "✅ No loop detected in network topology\n",
      "=== Output checker finished at: 2026-01-03 18:41:43  ===\n",
      "=== Output checker took      : 0:00:04.867866  ===========================\n",
      "=========================================================================\n"
     ]
    }
   ],
   "source": [
    "# read the file\n",
    "riv = gpd.read_file(riv_file)\n",
    "cat = gpd.read_file(cat_file)\n",
    "\n",
    "# create the folder if not existed\n",
    "org_folder = os.path.join(OutFolder, \"org\")\n",
    "if os.path.isdir(org_folder):\n",
    "    try:\n",
    "        shutil.rmtree(org_folder)\n",
    "    except OSError as e:\n",
    "        raise RuntimeError(f\"Failed to remove {org_folder}: {e}\")\n",
    "os.makedirs(org_folder, exist_ok=True)\n",
    "\n",
    "# save riv and cat\n",
    "riv.to_file(os.path.join(org_folder, \"riv.gpkg\"))\n",
    "cat.to_file(os.path.join(org_folder, \"cat.gpkg\"))\n",
    "\n",
    "# create the config and pass it to the Burn lake\n",
    "config = {\n",
    "    \"riv\": riv,\n",
    "    \"riv_dict\": {\n",
    "        \"COMID\": {\"col\":\"link_id\"},\n",
    "        \"NextDownCOMID\": {\"col\":\"ds_link_id\"},\n",
    "        \"length\": {\"col\":\"length\"},\n",
    "        \"uparea\": {\"col\":\"uparea\",\"unit\":\"km2\"}\n",
    "    },\n",
    "    \"cat\": cat,\n",
    "    \"cat_dict\": {\n",
    "        \"COMID\": {\"col\":\"link_id\"},\n",
    "        \"unitarea\": {\"col\":\"unitarea\",\"unit\":\"km2\"},\n",
    "    },\n",
    "    \"lake\": lake,\n",
    "    \"lake_dict\": {\n",
    "        \"LakeCOMID\": {\"col\":\"Hylak_id\"},\n",
    "        \"unitarea\": {\"col\":\"Lake_area\",\"unit\":\"km2\"}\n",
    "    },\n",
    "}\n",
    "\n",
    "# burn lakes into river network\n",
    "bl = BurnLakes(config)\n",
    "\n",
    "# create the folder if not existed\n",
    "corrected_folder = os.path.join(OutFolder, \"corrected\")\n",
    "if os.path.isdir(corrected_folder):\n",
    "    try:\n",
    "        shutil.rmtree(corrected_folder)\n",
    "    except OSError as e:\n",
    "        raise RuntimeError(f\"Failed to remove {corrected_folder}: {e}\")\n",
    "os.makedirs(corrected_folder, exist_ok=True)\n",
    "\n",
    "# save riv, cat, and lake\n",
    "bl.riv.to_file(os.path.join(corrected_folder, \"riv.gpkg\"))\n",
    "bl.cat.to_file(os.path.join(corrected_folder, \"cat.gpkg\"))\n",
    "bl.lake.to_file(os.path.join(corrected_folder, \"lake.gpkg\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ded78fd0-435d-45c3-8966-429e8e99a9df",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (RiverLakeEnv)",
   "language": "python",
   "name": "riverlakeenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
