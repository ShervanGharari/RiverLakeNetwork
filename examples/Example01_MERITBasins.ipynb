{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d2b002ab-19e6-4879-a9ee-fb1af8c6e464",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:tornado.general:Uncaught exception in ZMQStream callback\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/shg096/Desktop/RiverLakeNetwork/env/RiverLakeEnv/lib/python3.9/site-packages/traitlets/traitlets.py\", line 632, in get\n",
      "    value = obj._trait_values[self.name]\n",
      "KeyError: '_control_lock'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/shg096/Desktop/RiverLakeNetwork/env/RiverLakeEnv/lib/python3.9/site-packages/zmq/eventloop/zmqstream.py\", line 565, in _log_error\n",
      "    f.result()\n",
      "  File \"/Users/shg096/Desktop/RiverLakeNetwork/env/RiverLakeEnv/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 301, in dispatch_control\n",
      "    async with self._control_lock:\n",
      "  File \"/Users/shg096/Desktop/RiverLakeNetwork/env/RiverLakeEnv/lib/python3.9/site-packages/traitlets/traitlets.py\", line 687, in __get__\n",
      "    return t.cast(G, self.get(obj, cls))  # the G should encode the Optional\n",
      "  File \"/Users/shg096/Desktop/RiverLakeNetwork/env/RiverLakeEnv/lib/python3.9/site-packages/traitlets/traitlets.py\", line 649, in get\n",
      "    value = self._validate(obj, default)\n",
      "  File \"/Users/shg096/Desktop/RiverLakeNetwork/env/RiverLakeEnv/lib/python3.9/site-packages/traitlets/traitlets.py\", line 722, in _validate\n",
      "    value = self.validate(obj, value)\n",
      "  File \"/Users/shg096/Desktop/RiverLakeNetwork/env/RiverLakeEnv/lib/python3.9/site-packages/traitlets/traitlets.py\", line 2311, in validate\n",
      "    self.error(obj, value)\n",
      "  File \"/Users/shg096/Desktop/RiverLakeNetwork/env/RiverLakeEnv/lib/python3.9/site-packages/traitlets/traitlets.py\", line 831, in error\n",
      "    raise TraitError(e)\n",
      "traitlets.traitlets.TraitError: The '_control_lock' trait of an IPythonKernel instance expected a Lock, not the NoneType None.\n"
     ]
    }
   ],
   "source": [
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import hydrant.topology.geom as gm\n",
    "import subprocess\n",
    "import os\n",
    "from   shapely.geometry import Point\n",
    "import yaml\n",
    "import shutil\n",
    "import warnings\n",
    "import networkx as nx\n",
    "import re\n",
    "import copy\n",
    "from   riverlakenetwork import BurnLakes, Utility\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0a7a2e26-fa05-4168-87df-34553064827b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# outputfolder definition\n",
    "OutFolder = '/Users/shg096/Desktop/LakeRiverOut/'\n",
    "\n",
    "# location of merit basins bux fixed files\n",
    "riv_file_template='/Users/shg096/Desktop/MERIT_Hydro/riv/riv_pfaf_*_MERIT_Hydro_v07_Basins_v01_bugfix1.shp',\n",
    "cat_file_template='/Users/shg096/Desktop/MERIT_Hydro/cat/cat_pfaf_*_MERIT_Hydro_v07_Basins_v01_bugfix1.shp',\n",
    "cst_file_template='/Users/shg096/Desktop/MERIT_Hydro/hill/hillslope_*_clean.shp'\n",
    "\n",
    "# location of hydrolakes\n",
    "lake_file = '/Volumes/F:/hydrography/hydrolakes/HydroLAKES_polys_v10_shp/HydroLAKES_polys_v10_shp/HydroLAKES_polys_v10.shp'\n",
    "\n",
    "# pfaf to be computed\n",
    "pfafs = [\"71\", \"72\"]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5fabbfd-d2f5-43a5-85ed-da95dd268174",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=======================================================================\n",
      "=== Input loader started at : 2025-12-18 14:45:51  ===\n",
      "riv: Loaded\n",
      "riv_dict: {'COMID': {'col': 'COMID'}, 'NextDownCOMID': {'col': 'NextDownID'}, 'length': {'col': 'lengthkm'}, 'uparea': {'col': 'uparea', 'unit': 'km2'}}\n",
      "cat: Loaded\n",
      "cat_dict: {'COMID': {'col': 'COMID'}, 'unitarea': {'col': 'unitarea', 'unit': 'km2'}}\n",
      "lake: Loaded\n",
      "lake_dict: {'LakeCOMID': {'col': 'Hylak_id'}, 'unitarea': {'col': 'Lake_area', 'unit': 'km2'}}\n",
      "=== Input loader finished at: 2025-12-18 14:45:52  ===\n",
      "=== Input loader took      : 0:00:01.274374  ===========================\n",
      "=======================================================================\n",
      "========================================================================\n",
      "=== Input checker started at : 2025-12-18 14:45:52  ===\n",
      "Subbasin and lake area units are consistent: km2\n",
      "riv CRS: EPSG:4326\n",
      "cat CRS: EPSG:4326\n",
      "lake CRS: EPSG:4326\n",
      "=== Input checker finished at: 2025-12-18 14:45:53  ===\n",
      "=== Input checker took      : 0:00:01.373910  ===========================\n",
      "========================================================================\n",
      "==========================================================================\n",
      "=== Resolving lakes started at : 2025-12-18 14:45:53  ===\n",
      "==== Number of lakes after subsetting: 140586 ====\n"
     ]
    }
   ],
   "source": [
    "#load hydrolakeDataset\n",
    "lakeO = gpd.read_file(lake_file) # read the hydrolake dataset\n",
    "#lakeO = lakeO.loc[lakeO[\"Hylak_id\"] < 200].reset_index(drop=True)\n",
    "\n",
    "for pfaf in pfafs:\n",
    "\n",
    "    pfaf_base = f\"pfaf{pfaf}\"\n",
    "\n",
    "    # create the folder if not existed\n",
    "    org_folder = os.path.join(OutFolder, f\"{pfaf_base}_org\")\n",
    "    if os.path.isdir(org_folder):\n",
    "        try:\n",
    "            shutil.rmtree(org_folder)\n",
    "        except OSError as e:\n",
    "            raise RuntimeError(f\"Failed to remove {org_folder}: {e}\")\n",
    "    os.makedirs(org_folder, exist_ok=True)\n",
    "    \n",
    "    # read the pfaf merit folder\n",
    "    riv, cat = Utility.merit_read_file(pfaf,\n",
    "                                       riv_file_template='/Users/shg096/Desktop/MERIT_Hydro/riv/riv_pfaf_*_MERIT_Hydro_v07_Basins_v01_bugfix1.shp',\n",
    "                                       cat_file_template='/Users/shg096/Desktop/MERIT_Hydro/cat/cat_pfaf_*_MERIT_Hydro_v07_Basins_v01_bugfix1.shp',\n",
    "                                       cst_file_template='/Users/shg096/Desktop/MERIT_Hydro/hill/hillslope_*_clean.shp')\n",
    "    # save riv and cat\n",
    "    riv.to_file(os.path.join(org_folder, \"riv.gpkg\"))\n",
    "    cat.to_file(os.path.join(org_folder, \"cat.gpkg\"))\n",
    "\n",
    "    # create the folder if not existed\n",
    "    corrected_folder = os.path.join(OutFolder, f\"{pfaf_base}_corrected\")\n",
    "    if os.path.isdir(corrected_folder):\n",
    "        try:\n",
    "            shutil.rmtree(corrected_folder)\n",
    "        except OSError as e:\n",
    "            raise RuntimeError(f\"Failed to remove {corrected_folder}: {e}\")\n",
    "    os.makedirs(corrected_folder, exist_ok=True)\n",
    "    \n",
    "    # create the config and pass it to the Burn lake\n",
    "    config = {\n",
    "        \"riv\": riv,\n",
    "        \"riv_dict\": {\n",
    "            \"COMID\": {\"col\":\"COMID\"},\n",
    "            \"NextDownCOMID\": {\"col\":\"NextDownID\"},\n",
    "            \"length\": {\"col\":\"lengthkm\"},\n",
    "            \"uparea\": {\"col\":\"uparea\",\"unit\":\"km2\"}\n",
    "        },\n",
    "        \"cat\": cat,\n",
    "        \"cat_dict\": {\n",
    "            \"COMID\": {\"col\":\"COMID\"},\n",
    "            \"unitarea\": {\"col\":\"unitarea\",\"unit\":\"km2\"},\n",
    "        },\n",
    "        \"lake\": lakeO,\n",
    "        \"lake_dict\": {\n",
    "            \"LakeCOMID\": {\"col\":\"Hylak_id\"},\n",
    "            \"unitarea\": {\"col\":\"Lake_area\",\"unit\":\"km2\"}\n",
    "        },\n",
    "    }\n",
    "    \n",
    "    bl = BurnLakes(config)\n",
    "    bl.riv.to_file(os.path.join(corrected_folder, \"riv.gpkg\"))\n",
    "    bl.cat.to_file(os.path.join(corrected_folder, \"cat.gpkg\"))\n",
    "    bl.lake.to_file(os.path.join(corrected_folder, \"lake.gpkg\"))\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdb7c7c4-4f99-48f3-96c3-70c3d7cb1455",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (RiverLakeEnv)",
   "language": "python",
   "name": "riverlakeenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
